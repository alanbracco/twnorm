"""Evaluate normalization.

Usage:
  eval.py -r <gold_file> -g <generated_file> [-o <output_file>]
  eval.py -h | --help

Options:
  -r <gold_file>      Original corpus to compare results
  -g <generated_file> File generated by the normalizator
  -o <output_file>     Output file with normalization performance info
                       [default: stats.txt]
  -h --help            Show this screen.
"""
import os
import sys
from copy import copy
from docopt import docopt
from tweets_splitter import Tw_Splitter
from oov_picker import OOVpicker


class Evaluator(object):
    def __init__(self, output_file):
        self.output_file = output_file

    def my_write(self, *args, stdout=False):
        with open(self.output_file, 'a') as file:
            print(*args, file=file)
        if stdout:
            print(*args)

    def get_measure(self, gold_dict, generated_dict, tokenized):

        self.my_write("\nSTATISTICS")
        self.my_write("==========")

        set_gold_ids = set(gold_dict.keys())
        set_generated_ids = set(generated_dict.keys())

        both = sorted(list(set_gold_ids & set_generated_ids))
        missing_tweets = sorted(list(set_gold_ids - set_generated_ids))

        hits_corr = 0
        total = 0
        wrong_cl = 0
        wrong_co = 0
        misses = 0
        surpluses = 0
        unanalyzed = 0  # Quantity of words not analyzed
        total_missing_corr = 0  # Total number of corrections in 'gold' tweets

        oov_tp = 0  # Detected as OOV and it is OOV (True positives)
        oov_fp = 0  # Detected as OOV but it is not OOV (False positives)
        oov_tn = 0  # Not detected as OOV and it is not OOV (True Negatives)
        oov_fn = 0  # Not detected as OOV but it is OOV (False Negatives)
        total_words = 0  # Total number of words

        for tweet_id in missing_tweets:
            total_missing_corr += len(gold_dict[tweet_id])

        for tweet_id in both:
            gold_corrections = gold_dict[tweet_id]
            own_corrections = generated_dict[tweet_id]

            gold_words = [word for word, _, _ in gold_corrections]
            set_gold_words = set(gold_words)
            own_words = [word for word, _, _ in own_corrections]
            set_own_words = set(own_words)

            all_words = [word for j in tokenized[tweet_id].keys()
                         for word, _ in tokenized[tweet_id][j]]

            my_oov = copy(own_words)
            gold_oov = copy(gold_words)
            total_words += len(all_words)
            for word in all_words:
                if word in gold_oov and word in my_oov:
                    oov_tp += 1
                    my_oov.remove(word)
                    gold_oov.remove(word)
                elif word in gold_oov and word not in my_oov:
                    oov_fn += 1
                    gold_oov.remove(word)
                elif word not in gold_oov and word in my_oov:
                    oov_fp += 1
                    my_oov.remove(word)
                elif word not in gold_oov and word not in my_oov:
                    oov_tn += 1

            missing_words = set_gold_words - set_own_words
            surplus_words = set_own_words - set_gold_words
            both_words = set_gold_words & set_own_words
            conflict_words = missing_words | surplus_words

            if missing_words or surplus_words:
                self.my_write("\nTweetID:", tweet_id)
                self.my_write("-"*len("TweetID: " + tweet_id))
                if missing_words:
                    sorted_missing_words = sorted(list(missing_words))
                    misses += len(missing_words)
                    self.my_write("Missing words:", sorted_missing_words)
                    for word in sorted_missing_words:
                        correct_words = [c for w, _, c in gold_corrections
                                         if w == word]
                        if len(correct_words) > 1:
                            self.my_write("WARNING: There are more than one"
                                          " correction for '{}'. All "
                                          "corrections"
                                          " will be printed".format(word))
                        for correct_word in correct_words:
                            self.my_write(" - Word '{}' should be "
                                          "corrected as '{}'."
                                          "".format(word, correct_word))
                if surplus_words:
                    surpluses += len(surplus_words)
                    self.my_write("Surplus words:",
                                  sorted(list(surplus_words)))

            for word in sorted(list(both_words)):
                gold_tuples = [t for t in gold_corrections if t[0] == word]
                own_tuples = [t for t in own_corrections if t[0] == word]
                n_gold = len(gold_tuples)
                n_own = len(own_tuples)
                if n_gold != n_own:
                    unanalyzed += 1
                    self.my_write("WARNING: word", word, "not analized.")
                    self.my_write("You corrected", n_own, "time(s),",
                                  "but you have to correct it", n_gold,
                                  "time(s).")
                    self.my_write("DETAILS")
                    self.my_write("Actual corrections:", gold_tuples)
                    self.my_write("Current corrections:", own_tuples)
                else:
                    total += n_gold
                    for i in range(n_gold):
                        wg, clg, cog = gold_tuples[i]
                        wo, clo, coo = own_tuples[i]
                        assert wg == wo
                        if clg != clo:
                            wrong_cl += 1
                            wrong_co += 1
                            if clo == '1':
                                self.my_write(wo, "is not correct.",
                                              "The correct form is", cog)
                            elif clo == '2':
                                self.my_write(wo, "is not in English.",
                                              "The correct form is", cog)
                        else:
                            if cog != coo:
                                wrong_co += 1
                                self.my_write("You corrected", word, "as", coo,
                                              "but it is", cog)
                            else:
                                hits_corr += 1

        total += total_missing_corr

        assert total_words == oov_fn + oov_fp + oov_tn + oov_tp

        oov_accuracy = (oov_tp + oov_tn) / total_words
        oov_precision = oov_tp / (oov_tp + oov_fp)
        oov_recall = oov_tp / (oov_tp + oov_fn)

        co_accuracy = hits_corr / total

        self.my_write("\nSUMMARY", stdout=True)
        self.my_write("=======", stdout=True)
        if len(gold_dict) > 1:
            tweets = 'tweets'
        else:
            tweets = 'tweet'
        self.my_write("There are", len(gold_dict), tweets, "to correct.",
                      stdout=True)
        self.my_write("You corrected", len(generated_dict), stdout=True)
        self.my_write("#TweetsCorrected vs. #TweetsToBeCorrected:",
                      len(both), stdout=True)
        self.my_write("#TweetsCorrected vs. #TweetsNotToBeCorrected:",
                      len(set_generated_ids - set_gold_ids), stdout=True)
        self.my_write("#TweetsNotCorrected vs. #TweetsToBeCorrected:",
                      len(missing_tweets), stdout=True)
        self.my_write("You hit", hits_corr, "out of", total, "corrections (" +
                      str(total_missing_corr), "corrections are missing).",
                      stdout=True)
        self.my_write("The system MISCORRECTED", wrong_co, "words.",
                      stdout=True)
        if wrong_cl > 0:
            self.my_write(wrong_cl, "of these miscorrections are because the",
                          "system internally classified the word differently.",
                          stdout=True)
        self.my_write("Missing corrections:", misses, stdout=True)
        self.my_write("Surplus corrections:", surpluses, stdout=True)
        self.my_write("Words unanalyzed (corrected not equal times):",
                      unanalyzed, stdout=True)

        self.my_write("\nOOV detection", stdout=True)
        self.my_write("-------------", stdout=True)
        self.my_write("Accuracy:", round(oov_accuracy, 2), stdout=True)
        self.my_write("Precision:", round(oov_precision, 2), stdout=True)
        self.my_write("Recall:", round(oov_recall, 2), stdout=True)

        self.my_write("\nCorrections", stdout=True)
        self.my_write("-----------", stdout=True)
        self.my_write("Accuracy:", round(co_accuracy, 2), stdout=True)

        print("\nA detailed information can be found in '{}'"
              "".format(self.output_file))


if __name__ == '__main__':

    opts = docopt(__doc__)

    gold_file = opts['-r']
    gold_file_path = os.path.join(os.getcwd(), 'Input', gold_file)
    if not os.path.isfile(gold_file_path):
        print('You must enter an existing input file.')
        sys.exit()

    generated_file = opts['-g']
    generated_file_path = os.path.join(os.getcwd(), 'Output', generated_file)
    if not os.path.isfile(generated_file_path):
        print('You must enter an existing input file.')
        sys.exit()

    output_file = opts['-o']
    if output_file is None:
        output_file = 'stats.txt'
    if os.path.exists(output_file):
        os.remove(output_file)

    gold_splitter = Tw_Splitter(gold_file_path)
    generated_splitter = Tw_Splitter(generated_file_path)

    gold_dict = gold_splitter.corrections
    generated_dict = generated_splitter.corrections

    tokenized = OOVpicker(gold_splitter.texts).tokenized

    evaluator = Evaluator(output_file)
    evaluator.get_measure(gold_dict, generated_dict, tokenized)
