"""Evaluate normalization.

Usage:
  eval.py -r <gold_file> -g <generated_file> [-o <output_file>]
  eval.py -h | --help

Options:
  -r <gold_file>      Original corpus to compare results
  -g <generated_file> File generated by the normalizator
  -o <output_file>     Output file with normalization performance info
                       [default: stats.txt]
  -h --help            Show this screen.
"""
import os
import sys
from copy import copy
from docopt import docopt
from tweets_splitter import Tw_Splitter
from wta_picker import WTApicker


class Evaluator(object):
    def __init__(self, output_file):
        self.output_file = output_file

    def my_write(self, *args, stdout=False):
        with open(self.output_file, 'a') as file:
            print(*args, file=file)
        if stdout:
            print(*args)

    def get_measure(self, gold_dict, generated_dict, tokenized):

        self.my_write("\nSTATISTICS")
        self.my_write("==========")

        set_gold_ids = set(gold_dict.keys())
        set_generated_ids = set(generated_dict.keys())

        both = sorted(list(set_gold_ids & set_generated_ids))
        missing_tweets = sorted(list(set_gold_ids - set_generated_ids))
        surplus_tweets = sorted(list(set_generated_ids - set_gold_ids))

        hits_corr = 0  # Words corrected ok (quantity)
        wrong_cl = 0  # Wrong classification (quantity)
        wrong_co = 0  # Wrong corrections (quantity)
        misses = 0  # Missing corrections (quantity)
        surpluses = 0  # Surplus corrections (quantity)
        unanalyzed = 0  # Words not analyzed (quantity)
        total_gold_corr = 0  # Corrections in gold corpus (quantity)
        total_gen_corr = 0  # Corrections in generated corpus (quantity)
        total_missing_corr = 0  # Missing corrections (quantity)
        total_surplus_corr = 0  # Surplus corrections (quantity)

        wta_tp = 0  # Detected as WTA and it is WTA (True positives)
        wta_fp = 0  # Detected as WTA but it is not WTA (False positives)
        wta_tn = 0  # Not detected as WTA and it is not WTA (True Negatives)
        wta_fn = 0  # Not detected as WTA but it is WTA (False Negatives)
        total_words = 0  # Total number of words

        for tweet_id in missing_tweets:
            total_missing_corr += len(gold_dict[tweet_id])

        for tweet_id in surplus_tweets:
            total_surplus_corr += len(generated_dict[tweet_id])

        for tweet_id in both:
            gold_corrections = gold_dict[tweet_id]
            own_corrections = generated_dict[tweet_id]

            total_gold_corr += len(gold_corrections)
            total_gen_corr += len(own_corrections)

            gold_words = [word for word, _, _ in gold_corrections]
            set_gold_words = set(gold_words)
            own_words = [word for word, _, _ in own_corrections]
            set_own_words = set(own_words)

            all_words = [word for j in tokenized[tweet_id].keys()
                         for word, _ in tokenized[tweet_id][j]]

            my_wta = copy(own_words)
            gold_wta = copy(gold_words)
            total_words += len(all_words)
            for word in all_words:
                if word in gold_wta and word in my_wta:
                    wta_tp += 1
                    my_wta.remove(word)
                    gold_wta.remove(word)
                elif word in gold_wta and word not in my_wta:
                    wta_fn += 1
                    gold_wta.remove(word)
                elif word not in gold_wta and word in my_wta:
                    wta_fp += 1
                    my_wta.remove(word)
                elif word not in gold_wta and word not in my_wta:
                    wta_tn += 1

            missing_words = set_gold_words - set_own_words
            surplus_words = set_own_words - set_gold_words
            both_words = set_gold_words & set_own_words
            conflict_words = missing_words | surplus_words

            if (missing_words or surplus_words or
                    gold_corrections != own_corrections):
                self.my_write("\nTweetID:", tweet_id)
                self.my_write("-"*len("TweetID: " + tweet_id))

            if missing_words:
                sorted_missing_words = sorted(list(missing_words))
                misses += len(missing_words)
                self.my_write("Missing words:", sorted_missing_words)
                for word in sorted_missing_words:
                    correct_words = [c for w, _, c in gold_corrections
                                     if w == word]
                    if len(correct_words) > 1:
                        self.my_write("WARNING: There are more than one"
                                      " correction for '{}'. All "
                                      "corrections"
                                      " will be printed".format(word))
                    for correct_word in correct_words:
                        self.my_write(" - Word '{}' should be "
                                      "corrected as '{}'."
                                      "".format(word, correct_word))
            if surplus_words:
                surpluses += len(surplus_words)
                self.my_write("Surplus words:",
                              sorted(list(surplus_words)))

            for word in sorted(list(both_words)):
                gold_tuples = [t for t in gold_corrections if t[0] == word]
                own_tuples = [t for t in own_corrections if t[0] == word]
                n_gold = len(gold_tuples)
                n_own = len(own_tuples)
                if n_gold != n_own:
                    unanalyzed += 1
                    self.my_write("WARNING: word", word, "not analized.")
                    self.my_write("You corrected", n_own, "time(s),",
                                  "but you have to correct it", n_gold,
                                  "time(s).")
                    self.my_write("DETAILS")
                    self.my_write("Actual corrections:", gold_tuples)
                    self.my_write("Current corrections:", own_tuples)
                else:
                    for i in range(n_gold):
                        wg, clg, cog = gold_tuples[i]
                        wo, clo, coo = own_tuples[i]
                        assert wg == wo
                        if clg != clo:
                            wrong_cl += 1
                            wrong_co += 1
                            if clo == '1':
                                self.my_write(wo, "is not correct.",
                                              "The correct form is", cog)
                            elif clo == '2':
                                self.my_write(wo, "is not in English.",
                                              "The correct form is", cog)
                        else:
                            if cog != coo:
                                wrong_co += 1
                                self.my_write("You corrected", word, "as", coo,
                                              "but it is", cog)
                            else:
                                hits_corr += 1

        total_gold_corr += total_missing_corr
        total_gen_corr += total_surplus_corr

        assert total_words == wta_fn + wta_fp + wta_tn + wta_tp

        wta_accuracy = (wta_tp + wta_tn) / total_words
        wta_precision = wta_tp / (wta_tp + wta_fp)
        wta_recall = wta_tp / (wta_tp + wta_fn)

        co_precision = hits_corr / total_gen_corr
        co_recall = hits_corr / total_gold_corr

        self.my_write("\nSUMMARY", stdout=True)
        self.my_write("=======", stdout=True)
        if len(gold_dict) > 1:
            tweets = 'tweets'
        else:
            tweets = 'tweet'
        self.my_write("There are", len(gold_dict), tweets, "to correct.",
                      stdout=True)
        self.my_write("You corrected", len(generated_dict), stdout=True)
        self.my_write("#TweetsCorrected vs. #TweetsToBeCorrected:",
                      len(both), stdout=True)
        self.my_write("#TweetsCorrected vs. #TweetsNotToBeCorrected:",
                      len(surplus_tweets), stdout=True)
        self.my_write("#TweetsNotCorrected vs. #TweetsToBeCorrected:",
                      len(missing_tweets), stdout=True)
        self.my_write("The system MISCORRECTED", wrong_co, "words.",
                      stdout=True)
        if wrong_cl > 0:
            self.my_write(wrong_cl, "of these miscorrections are because the",
                          "system internally classified the word differently.",
                          stdout=True)
        self.my_write("Missing corrections:", misses, stdout=True)
        self.my_write("Surplus corrections:", surpluses, stdout=True)
        if unanalyzed > 0:
            self.my_write("Words unanalyzed",
                          "(corrected not equal times in the tweet):",
                          unanalyzed, stdout=True)

        self.my_write("\nWTA detection", stdout=True)
        self.my_write("-------------", stdout=True)
        self.my_write("Accuracy:", round(wta_accuracy, 2), stdout=True)
        self.my_write("Precision:", round(wta_precision, 2), stdout=True)
        self.my_write("Recall:", round(wta_recall, 2), stdout=True)

        self.my_write("\nCorrections", stdout=True)
        self.my_write("-----------", stdout=True)
        self.my_write("Precision:", round(co_precision, 2), stdout=True)
        self.my_write("Recall:", round(co_recall, 2), stdout=True)

        print("\nA detailed information can be found in '{}'"
              "".format(self.output_file))


if __name__ == '__main__':

    opts = docopt(__doc__)

    gold_file = opts['-r']
    gold_file_path = os.path.join(os.getcwd(), 'Input', gold_file)
    if not os.path.isfile(gold_file_path):
        print('You must enter an existing input file.')
        sys.exit()

    generated_file = opts['-g']
    generated_file_path = os.path.join(os.getcwd(), 'Output', generated_file)
    if not os.path.isfile(generated_file_path):
        print('You must enter an existing input file.')
        sys.exit()

    output_file = opts['-o']
    if output_file is None:
        output_file = 'stats.txt'
    output_file = 'Stats/' + output_file
    if os.path.exists(output_file):
        os.remove(output_file)

    gold_splitter = Tw_Splitter(gold_file_path)
    generated_splitter = Tw_Splitter(generated_file_path)

    gold_dict = gold_splitter.corrections
    generated_dict = generated_splitter.corrections

    tokenized = WTApicker(gold_splitter.texts).tokenized

    evaluator = Evaluator(output_file)
    evaluator.get_measure(gold_dict, generated_dict, tokenized)
