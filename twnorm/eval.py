"""Evaluate normalization.

Usage:
  evalnorm -r <gold_file> -g <generated_file> [-o <output_file>]
  evalnorm -h | --help

Options:
  -r <gold_file>      Original corpus to compare results
  -g <generated_file> File generated by the normalizator
  -o <output_file>     Output file with normalization performance info
                       [default: stats.txt]
  -h --help            Show this screen.
"""
import os
import sys
from copy import copy
from docopt import docopt
from collections import Counter, defaultdict
from twnorm.aux import to_str_perc
from twnorm.tweets_splitter import Splitter


class Evaluator(object):
    def __init__(self, output_file):
        self.output_file = output_file

    def my_write(self, *args, stdout=False):
        with open(self.output_file, 'a') as file:
            print(*args, file=file)
        if stdout:
            print(*args)

    def print_symdiff_tweets(self, tweets_ids, tweets_dict, missing=True):
        if missing:
            header = "MISSING TWEETS"
            dashes = '-' * len(header)
            msg = "  - '{}' was not detected as WTA."
        else:
            header = "SURPLUS TWEETS"
            dashes = '-' * len(header)
            msg = "  - '{}' should not be detected as WTA."

        self.my_write(header)
        self.my_write(dashes)
        for tweet_id in tweets_ids:
            header = "TweetID: {tweet_id}".format(tweet_id=tweet_id)
            self.my_write(header)
            for wta, _, _ in tweets_dict[tweet_id]:
                self.my_write(msg.format(wta))

    def print_conflict_tweets(self, tweets_ids, gold_dict, gen_dict):

        header = "CONFLICTIVE TWEETS"
        dashes = '-' * len(header)

        self.my_write(header)
        self.my_write(dashes)

        for tweet_id in tweets_ids:
            gold_corr = defaultdict(list)
            for wd, _, corr in gold_dict[tweet_id]:
                gold_corr[wd].append(corr)
            gold_corr = dict(gold_corr)

            gen_corr = defaultdict(list)
            for wd, _, corr in gen_dict[tweet_id]:
                gen_corr[wd].append(corr)
            gen_corr = dict(gen_corr)

            missing_words = [word for word in gold_corr.keys()
                             if word not in gen_corr.keys()]

            surplus_words = [word for word in gen_corr.keys()
                             if word not in gold_corr.keys()]

            both_keys = set(gen_corr.keys()) & set(gold_corr.keys())
            conflictive_words = [word for word in both_keys
                                 if gold_corr[word] != gen_corr[word]]

            if missing_words or surplus_words or conflictive_words:
                header = "TweetID: {tweet_id}".format(tweet_id=tweet_id)
                self.my_write(header)

                if missing_words:
                    self.my_write("  Missing words:", sorted(missing_words))
                if surplus_words:
                    self.my_write("  Surplus words:", sorted(surplus_words))
                for word in sorted(conflictive_words):
                    if len(gold_corr[word]) == len(gen_corr[word]) == 1:
                        self.my_write("  - '{}' was corrected as '{}' "
                                      "but it is '{}'"
                                      "".format(word, gen_corr[word][0],
                                                gold_corr[word][0]))
                    else:
                        self.my_write("  - Corrections for '{}' are {}\n"
                                      "    but you corrected as {}"
                                      "".format(word, gold_corr[word],
                                                gen_corr[word]))

    def get_true_positives(self, gold_dict, gen_dict, for_correction=False):

        hits = 0
        tweet_ids = sorted(list(set(gold_dict.keys()) & set(gen_dict.keys())))

        for tweet_id in tweet_ids:
            current_hits = 0

            gold = gold_dict[tweet_id]
            generated = gen_dict[tweet_id]
            if not for_correction:
                gold = [w for w, _, _ in gold]
                generated = [w for w, _, _ in generated]

            current_hits += len(set(gold) & set(generated))

            gold_counter = Counter(gold)
            gen_counter = Counter(generated)
            for key, times in gold_counter.items():
                if key in generated and times > 1:
                    # Minus 1 because the first count appears in
                    # conjunction of gold and generated sets
                    current_hits += times - 1
            hits += current_hits

        return hits

    def get_accuracy(self, gold_dict, gen_dict, all_tokens,
                     for_correction=False):

        # Start with True positives count
        hits = self.get_true_positives(gold_dict, gen_dict, for_correction)

        # Calculate True Negatives
        for tweet_id in all_tokens:
            current_hits = 0
            tokens = all_tokens[tweet_id]

            if tweet_id in gold_dict and tweet_id in gen_dict:
                gold_tokens = [w for w, _, _ in gold_dict[tweet_id]]
                gen_tokens = [w for w, _, _ in gen_dict[tweet_id]]
                for token in tokens:
                    if token not in gold_tokens and token not in gen_tokens:
                        current_hits += 1
                    else:
                        if token in gold_tokens:
                            gold_tokens.remove(token)

                        if token in gen_tokens:
                            gen_tokens.remove(token)

            elif tweet_id not in gold_dict and tweet_id not in gen_dict:
                current_hits += len(tokens)

            elif tweet_id in gold_dict and tweet_id not in gen_dict:
                current_hits += len(tokens) - len(gold_dict[tweet_id])

            else:
                current_hits += len(tokens) - len(gen_dict[tweet_id])

            hits += current_hits

        total_tokens = sum(len(all_tokens[twt_id]) for twt_id in all_tokens)
        accuracy = hits / total_tokens

        return accuracy

    def get_precision_and_recall(self, gold_dict, gen_dict,
                                 for_correction=False):

        total_gold_wta = sum([len(gold_dict[x]) for x in gold_dict])
        total_gen_wta = sum([len(gen_dict[x]) for x in gen_dict])

        hits = self.get_true_positives(gold_dict, gen_dict, for_correction)

        precision = hits / total_gen_wta
        recall = hits / total_gold_wta

        return precision, recall

    def get_measures(self, gold_dict, gen_dict, all_tokens):

        # WTA detection metrics
        wta_precision, wta_recall = self.get_precision_and_recall(gold_dict,
                                                                  gen_dict)
        wta_accuracy = self.get_accuracy(gold_dict, gen_dict, all_tokens)

        # WTA correction metrics
        corr_precision, corr_recall = self.get_precision_and_recall(
                                        gold_dict, gen_dict,
                                        for_correction=True)
        corr_accuracy = self.get_accuracy(gold_dict, gen_dict, all_tokens,
                                          for_correction=True)

        wta_tuple = (wta_accuracy, wta_precision, wta_recall)
        corr_tuple = (corr_accuracy, corr_precision, corr_recall)

        return wta_tuple, corr_tuple

    def write_detailed_info(self, gold_dict, gen_dict):

        set_gold_ids = set(gold_dict.keys())
        set_generated_ids = set(gen_dict.keys())

        # Tweets that appear in gold and generated
        both = sorted(list(set_gold_ids & set_generated_ids))
        # Tweets that only appear in gold
        missing_tweets = sorted(list(set_gold_ids - set_generated_ids))
        # Tweets that only appear in generated
        surplus_tweets = sorted(list(set_generated_ids - set_gold_ids))

        if missing_tweets or surplus_tweets or both:
            header = "DETAILED INFO"
            self.my_write(header)
            self.my_write('=' * len(header))
            self.my_write()

        if missing_tweets:
            self.print_symdiff_tweets(missing_tweets, gold_dict, missing=True)
            self.my_write()

        if surplus_tweets:
            self.print_symdiff_tweets(surplus_tweets, gen_dict, missing=False)
            self.my_write()

        if both:
            self.print_conflict_tweets(both, gold_dict, gen_dict)
            self.my_write()

    def write_summary(self, gold_dict, gen_dict, all_tokens):

        gold_ids = set(gold_dict.keys())
        gen_ids = set(gen_dict.keys())
        tp_tweets = gold_ids & gen_ids
        fp_tweets = gen_ids - gold_ids
        fn_tweets = gold_ids - gen_ids
        tweets_to_correct = len(gold_ids)

        missing_corrections = sum([len(gold_dict[tid]) for tid in fn_tweets])
        surplus_corrections = sum([len(gen_dict[tid]) for tid in fp_tweets])

        wta_tuple, corr_tuple = self.get_measures(gold_dict, gen_dict,
                                                  all_tokens)

        wta_accuracy = wta_tuple[0]
        wta_precision = wta_tuple[1]
        wta_recall = wta_tuple[2]

        corr_accuracy = corr_tuple[0]
        corr_precision = corr_tuple[1]
        corr_recall = corr_tuple[2]

        header = "SUMMARY"
        self.my_write(header, stdout=True)
        self.my_write('=' * len(header), stdout=True)
        self.my_write("#TweetsToCorrect:", tweets_to_correct, stdout=True)
        self.my_write("#TweetsCorrected vs. #TweetsToBeCorrected:",
                      len(tp_tweets), stdout=True)
        self.my_write("#TweetsCorrected vs. #TweetsNotToBeCorrected:",
                      len(fp_tweets), stdout=True)
        self.my_write("#TweetsNotCorrected vs. #TweetsToBeCorrected:",
                      len(fn_tweets), stdout=True)
        self.my_write("Missing corrections:", missing_corrections, stdout=True)
        self.my_write("Surplus corrections:", surplus_corrections, stdout=True)
        self.my_write(stdout=True)
        self.my_write("WTA detecion", stdout=True)
        self.my_write("------------", stdout=True)
        self.my_write("Accuracy:", to_str_perc(wta_accuracy), stdout=True)
        self.my_write("Precision:", to_str_perc(wta_precision), stdout=True)
        self.my_write("Recall:", to_str_perc(wta_recall), stdout=True)
        self.my_write(stdout=True)
        self.my_write("WTA correction", stdout=True)
        self.my_write("------------", stdout=True)
        self.my_write("Accuracy:", to_str_perc(corr_accuracy), stdout=True)
        self.my_write("Precision:", to_str_perc(corr_precision), stdout=True)
        self.my_write("Recall:", to_str_perc(corr_recall), stdout=True)

    def build_output_stats(self, gold_dict, gen_dict, all_tokens):
        self.my_write("STATISTICS")
        self.my_write("==========\n")

        self.write_summary(gold_dict, gen_dict, all_tokens)
        self.my_write()
        self.write_detailed_info(gold_dict, gen_dict)


def evaluate():

    opts = docopt(__doc__)

    abs_current_path = os.path.dirname(os.path.abspath(__file__))
    project_root_path = os.path.join(abs_current_path, '..')

    gold_file = opts['-r']
    gold_file_path = os.path.join(project_root_path, 'Input', gold_file)
    if not os.path.isfile(gold_file_path):
        print('You must enter an existing input file.')
        sys.exit()

    generated_file = opts['-g']
    generated_file_path = os.path.join(project_root_path, 'Output',
                                       generated_file)
    if not os.path.isfile(generated_file_path):
        print('You must enter an existing input file.')
        sys.exit()

    output_file = opts['-o']
    if output_file is None:
        output_file = 'stats.txt'
    output_file_path = os.path.join(project_root_path, 'Stats/', output_file)
    if os.path.exists(output_file_path):
        os.remove(output_file_path)

    gold_splitter = Splitter(gold_file_path)
    gold_dict = gold_splitter.corrections

    generated_splitter = Splitter(generated_file_path)
    generated_dict = generated_splitter.corrections

    all_tokens = gold_splitter.get_all_tokens()

    evaluator = Evaluator(output_file_path)
    evaluator.build_output_stats(gold_dict, generated_dict, all_tokens)


if __name__ == '__main__':
    evaluate()
